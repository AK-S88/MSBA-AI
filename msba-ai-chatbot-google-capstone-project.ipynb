{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11427792,"sourceType":"datasetVersion","datasetId":7157316},{"sourceId":11427800,"sourceType":"datasetVersion","datasetId":7157323},{"sourceId":11428162,"sourceType":"datasetVersion","datasetId":7157592},{"sourceId":234151043,"sourceType":"kernelVersion"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# üéì MSBA Program Chatbot with RAG Pipeline\n\nThis project builds a domain-specific AI chatbot using **Retrieval-Augmented Generation (RAG)** to answer questions about the Master of Science in Business Analytics (MSBA) program at UMass Lowell.\n\nIt was developed as a submission for the **Google GenAI Intensive Capstone Project**.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-18T21:15:23.847386Z","iopub.execute_input":"2025-04-18T21:15:23.847815Z","iopub.status.idle":"2025-04-18T21:15:23.855381Z","shell.execute_reply.started":"2025-04-18T21:15:23.847791Z","shell.execute_reply":"2025-04-18T21:15:23.854054Z"}}},{"cell_type":"markdown","source":"## üì¶ Step 1: Install Required Libraries\n\nWe begin by installing necessary libraries:\n- `PyMuPDF` for PDF text extraction\n- `sentence-transformers` for text embeddings\n- `faiss-cpu` for fast similarity search\n","metadata":{}},{"cell_type":"code","source":"!pip install -q PyMuPDF faiss-cpu sentence-transformers transformers peft accelerate bitsandbytes ipywidgets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:25:41.457668Z","iopub.execute_input":"2025-04-19T21:25:41.458005Z","iopub.status.idle":"2025-04-19T21:27:06.983999Z","shell.execute_reply.started":"2025-04-19T21:25:41.457979Z","shell.execute_reply":"2025-04-19T21:27:06.983098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìö Step 2: Import Libraries\n\nNext, we import standard libraries like Pandas and NumPy, NLP tools like NLTK, embedding tools from Sentence Transformers, and Hugging Face‚Äôs QA pipeline.\n","metadata":{}},{"cell_type":"code","source":"# Imports\nimport os\nimport fitz  # PyMuPDF\nimport faiss\nimport torch\nimport json\nimport numpy as np\nimport pandas as pd\nimport re\nimport nltk\nimport ipywidgets as widgets\nfrom nltk.tokenize import sent_tokenize\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom peft import PeftModel\n\nnltk.download('punkt')\n\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:27:06.985063Z","iopub.execute_input":"2025-04-19T21:27:06.985293Z","iopub.status.idle":"2025-04-19T21:27:36.886534Z","shell.execute_reply.started":"2025-04-19T21:27:06.985266Z","shell.execute_reply":"2025-04-19T21:27:36.885707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load flan-t5-base for generation\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\nmodel.eval()\n\n# Load encoder\nencoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:27:36.888019Z","iopub.execute_input":"2025-04-19T21:27:36.888522Z","iopub.status.idle":"2025-04-19T21:27:50.969042Z","shell.execute_reply.started":"2025-04-19T21:27:36.888504Z","shell.execute_reply":"2025-04-19T21:27:50.968230Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîç Step 3: Chunk, Embed, and Index Program Data\n\nWe load two sources:\n- MSBA Course Handbook (PDF)\n- Scraped MSBA content from the university website\n\nThen we:\n1. Clean and chunk the content into readable units\n2. Generate semantic embeddings using `all-mpnet-base-v2`\n3. Store them in a FAISS vector index for fast nearest-neighbor search\n","metadata":{}},{"cell_type":"code","source":"\ndef clean_text(text):\n    if isinstance(text, str):\n        text = re.sub(r'<[^>]*>', '', text)\n        text = re.sub(r'\\s+', ' ', text).strip()\n        text = re.sub(r'[^\\w\\s]', '', text)\n        return text\n    else:\n        return \"\"\n\ndef chunk_text(text, max_chunk_length=500, overlap=50):\n    if not text:\n        return []\n    sentences = sent_tokenize(text)\n    chunks = []\n    current_chunk = \"\"\n    for sentence in sentences:\n        if len(current_chunk) + len(sentence) + 1 <= max_chunk_length:\n            current_chunk += sentence + \" \"\n        else:\n            if current_chunk:\n                chunks.append(current_chunk.strip())\n            current_chunk = sentence + \" \"\n    if current_chunk:\n        chunks.append(current_chunk.strip())\n    return chunks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:27:50.969884Z","iopub.execute_input":"2025-04-19T21:27:50.970143Z","iopub.status.idle":"2025-04-19T21:27:50.978759Z","shell.execute_reply.started":"2025-04-19T21:27:50.970118Z","shell.execute_reply":"2025-04-19T21:27:50.978101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef extract_text_from_pdf(pdf_path):\n    doc = fitz.open(pdf_path)\n    text = \"\"\n    for page in doc:\n        text += page.get_text()\n    return text\n\npdf_path = \"/kaggle/input/msba-handbook-2024/MSBA Handbook 2024-2024.pdf\"  \npdf_text = extract_text_from_pdf(pdf_path)\ncleaned_pdf_text = clean_text(pdf_text)\npdf_chunks = chunk_text(cleaned_pdf_text)\npdf_df = pd.DataFrame({'text_chunk': pdf_chunks})\npdf_df['source'] = 'course_catalog'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:27:50.979681Z","iopub.execute_input":"2025-04-19T21:27:50.980142Z","iopub.status.idle":"2025-04-19T21:27:54.791568Z","shell.execute_reply.started":"2025-04-19T21:27:50.979960Z","shell.execute_reply":"2025-04-19T21:27:54.791038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pdf_df = pd.DataFrame({'text_chunk': pdf_chunks})\n# Load only the text from scraped data (ignore embeddings)\nscraped_raw = pd.read_csv(\"/kaggle/input/scraped-data-embeddings/raw_chunks_with_embeddings_scraped_data.csv\")\nscraped_df = scraped_raw[['text_chunk']].copy()\nscraped_df['text_chunk'] = scraped_df['text_chunk'].astype(str).fillna('')\nscraped_df['source'] = 'scraped'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:27:54.792299Z","iopub.execute_input":"2025-04-19T21:27:54.792522Z","iopub.status.idle":"2025-04-19T21:27:54.954565Z","shell.execute_reply.started":"2025-04-19T21:27:54.792505Z","shell.execute_reply":"2025-04-19T21:27:54.954019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine all text chunks for embedding\ncombined_df = pd.concat([scraped_df, pdf_df], ignore_index=True)\n\n# Generate new embeddings using mpnet\nencoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\nembeddings = encoder.encode(combined_df['text_chunk'].tolist(), show_progress_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:27:54.955306Z","iopub.execute_input":"2025-04-19T21:27:54.955562Z","iopub.status.idle":"2025-04-19T21:28:01.652025Z","shell.execute_reply.started":"2025-04-19T21:27:54.955544Z","shell.execute_reply":"2025-04-19T21:28:01.651287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate embeddings and FAISS index\nembeddings = encoder.encode(combined_df['text_chunk'].tolist(), show_progress_bar=True)\nindex = faiss.IndexFlatL2(embeddings.shape[1])\nindex.add(np.array(embeddings).astype(\"float32\"))\nmetadata_df = combined_df.copy()\nmetadata_df['embedding'] = embeddings.tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:28:01.653029Z","iopub.execute_input":"2025-04-19T21:28:01.653407Z","iopub.status.idle":"2025-04-19T21:28:07.189595Z","shell.execute_reply.started":"2025-04-19T21:28:01.653369Z","shell.execute_reply":"2025-04-19T21:28:07.189036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ü§ñ Step 4: Retrieval and Context Builder\n\nWhen a user asks a question, we:\n1. Embed the query into a vector\n2. Use FAISS to retrieve semantically similar chunks\n3. Combine the top matches into a context window for the answer model\n","metadata":{}},{"cell_type":"code","source":"# Embedding & Search\ndef get_embedding(text):\n    return encoder.encode([text])[0]\n\n\n\n\n\ndef search_faiss(query, top_k=5):\n    query_vector = get_embedding(query).astype(\"float32\")\n    D, I = index.search(np.array([query_vector]), top_k)\n    return I[0]\n\n\n\n\n\"\"\"# cosine similarity HELPER function\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef rerank_by_cosine(query_embedding, chunk_embeddings, top_k=5):\n    similarities = cosine_similarity([query_embedding], chunk_embeddings)[0]\n    top_indices = similarities.argsort()[-top_k:][::-1]\n    return top_indices\n\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:28:07.191746Z","iopub.execute_input":"2025-04-19T21:28:07.192001Z","iopub.status.idle":"2025-04-19T21:28:07.198574Z","shell.execute_reply.started":"2025-04-19T21:28:07.191982Z","shell.execute_reply":"2025-04-19T21:28:07.197840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Truncated Context Retrieval\n\ndef get_context_from_indices(indices, max_chars=2000):\n    texts = metadata_df.iloc[indices]['text_chunk']\n    top_clean = []\n    for t in texts:\n        if 30 < len(t) < 555:  # keep short-medium useful chunks\n            top_clean.append(t.strip())\n        if len(\" \".join(top_clean)) > max_chars:\n            break\n    return \"\\n\".join(top_clean)[:max_chars]\n\n\n\"\"\"\ndef get_context_from_indices(indices, max_chars=1500):\n    texts = metadata_df.iloc[indices]['text_chunk']\n    combined = \"\\n---\\n\".join(texts)\n    return combined[:max_chars]\n\"\"\"\n\n\n\n\"\"\"\n# Load fine-tuned LoRA adapter on top of flan-t5-base\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\nmodel = PeftModel.from_pretrained(base_model, \"./peft-msba-flant5\")\nmodel.eval()\n\n\n\"\"\"\n\n\nEXAMPLES = \"\"\"\\\nQ: How many credits are required to complete the MSBA program?\nA: The MSBA program requires 30 credits to complete.\n\nQ: What are the core courses in the MSBA program?\nA: The MSBA core courses include MIST.6030, MIST.6060, MIST.6150, POMS.6120, POMS.6220, POMS.6240, and either the Capstone (MIST.6490) or Internship (MIST.6890).\n\nQ: Can I specialize in something within the MSBA?\nA: Yes, the MSBA program offers six specialization tracks, including Accounting Analytics, Big Data Analytics, Finance Analytics, Healthcare Business Analytics, Managerial Decision Making, and Marketing Analytics.\n\nQ: How long does it take to finish the MSBA program?\nA: Students typically complete the MSBA program in 18 months to 3 years, depending on course load.\n\nQ: Is there a capstone requirement in the MSBA program?\nA: Yes, students must complete either a capstone project (MIST.6490) or an internship (MIST.6890) as part of the MSBA core.\n\nQ: What is MIST.6890?\nA: MIST.6890 is a 3-credit internship course where students apply analytics skills in a real-world job setting and complete a reflective paper.\n\nQ: Are there prerequisites for the MSBA program?\nA: Yes, students must complete introductory courses in Statistics and Management Information Systems, either before or during their first semester.\n\nQ: Is the MSBA program flexible for working students?\nA: Yes, the program is flexible and offers part-time study, semester-based entry, and both online and on-campus formats.\n\nQ: Is the MSBA program STEM-designated?\nA: Yes, the MSBA program is STEM-designated, making international students eligible for a 24-month OPT extension.\n\nQ: What is the cost of online courses in the MSBA program?\nA: Each 3-credit online course in the MSBA program costs $1,965, plus a $30 semester fee.\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:28:07.199494Z","iopub.execute_input":"2025-04-19T21:28:07.199735Z","iopub.status.idle":"2025-04-19T21:28:07.213782Z","shell.execute_reply.started":"2025-04-19T21:28:07.199720Z","shell.execute_reply":"2025-04-19T21:28:07.213046Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üß† Step 5: Natural Language Answer Generator\n\nWe use `flan-t5-base` to generate a full-sentence answer. The prompt includes:\n- Few-shot examples from our training data (10 Q&A)\n- Retrieved program context\n- The user‚Äôs current question\n","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\ngenerator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n\n\ndef generate_response_local(query, context):\n    prompt = (\n        f\"You are an MSBA program assistant. Based on the context and examples below, answer clearly in one or two full sentences.\\n\\n\"\n        \"Here is some relevant program information:\\n\"\n        f\"{EXAMPLES}\\n\"\n        f\"{context}\\n\\n\"\n        \"Q: How many credits are required to complete the MSBA program?\\n\"\n        \"A: The MSBA program requires 30 credits to complete.\\n\\n\"\n        f\"Q: {query}\\n\"\n        \"A:\"\n    )\n    output = generator(prompt, max_new_tokens=800, do_sample=True)\n    answer = output[0]['generated_text'].strip()\n    \n    # Postprocess: Add fallback if answer is too short\n\n    if len(answer.split()) < 4:\n        answer += \" (Sorry, the context might be too limited. Try rephrasing your question.)\"\n    \n    return answer\n\"\"\"\ndef generate_response_local(query, context):\n    prompt = (\n        f\"You are an MSBA program assistant. Based on the context below, answer clearly in one or two full sentences.\\n\\n\"\n        f\"{context}\\n\\n\"\n        f\"Question: {query}\\n\"\n        f\"Answer:\"\n    )\n    input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n\n    with torch.no_grad():\n        output_ids = model.generate(input_ids, max_new_tokens=256, do_sample=False)\n\n    return tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:28:07.214782Z","iopub.execute_input":"2025-04-19T21:28:07.215059Z","iopub.status.idle":"2025-04-19T21:28:22.542373Z","shell.execute_reply.started":"2025-04-19T21:28:07.215038Z","shell.execute_reply":"2025-04-19T21:28:22.541580Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üí¨ Step 6: Chat Interface (Interactive Bot)\n\nWe build a persistent chatbot UI using `ipywidgets`. \nThis interface:\n- Keeps the full chat history visible\n- Lets the user ask follow-up questions\n- Refreshes continuously without clearing previous messages\n","metadata":{}},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display\n\n# Text input\ninput_box = widgets.Text(\n    value='',\n    placeholder='Ask something about the MSBA program...',\n    description='You:',\n    layout=widgets.Layout(width='100%')\n)\n\n# Submit button\nsubmit_button = widgets.Button(description=\"Ask Bot ü§ñ\", button_style='primary')\noutput_box = widgets.Output()\n\n# Chatbot logic\ndef on_submit(_):\n    output_box.clear_output()\n    with output_box:\n        user_query = input_box.value.strip()\n        print(\"You asked:\", user_query)\n\n        if not user_query:\n            print(\"‚ö†Ô∏è Please enter a question.\")\n            return\n\n        indices = search_faiss(user_query)\n        context = get_context_from_indices(indices)\n        answer = generate_response_local(user_query, context)\n\n        print(\"Bot says:\", answer)\n\n# Hook up the button to the function\nsubmit_button.on_click(on_submit)\n\n# Display UI\ndisplay(input_box, submit_button, output_box)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:28:22.543292Z","iopub.execute_input":"2025-04-19T21:28:22.543598Z","iopub.status.idle":"2025-04-19T21:28:22.561507Z","shell.execute_reply.started":"2025-04-19T21:28:22.543574Z","shell.execute_reply":"2025-04-19T21:28:22.560857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display\n\n# Text input\ninput_box = widgets.Text(\n    value='',\n    placeholder='Ask something about the MSBA program...',\n    description='You:',\n    layout=widgets.Layout(width='100%')\n)\n\n# Submit button\nsubmit_button = widgets.Button(description=\"Ask Bot ü§ñ\", button_style='primary')\noutput_box = widgets.Output()\n\n# Chatbot logic\ndef on_submit(_):\n    output_box.clear_output()\n    with output_box:\n        user_query = input_box.value.strip()\n        print(\"You asked:\", user_query)\n\n        if not user_query:\n            print(\"‚ö†Ô∏è Please enter a question.\")\n            return\n\n        indices = search_faiss(user_query)\n        context = get_context_from_indices(indices)\n        answer = generate_response_local(user_query, context)\n\n        print(\"Bot says:\", answer)\n\n# Hook up the button to the function\nsubmit_button.on_click(on_submit)\n\n# Display UI\ndisplay(input_box, submit_button, output_box)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:28:22.562363Z","iopub.execute_input":"2025-04-19T21:28:22.562635Z","iopub.status.idle":"2025-04-19T21:28:27.871777Z","shell.execute_reply.started":"2025-04-19T21:28:22.562614Z","shell.execute_reply":"2025-04-19T21:28:27.871017Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚úÖ Submission Summary\n\nThis notebook showcases a production-ready RAG chatbot using open-source tools only ‚Äî no training required. The solution uses:\n- Semantically indexed program data (from PDFs and scraped pages)\n- Prompt-level few-shot learning (via handcrafted examples)\n- A minimal and persistent notebook UI\n\nThis project was submitted as part of the **Google GenAI Intensive Capstone Program**.\n","metadata":{}},{"cell_type":"code","source":"metadata_df[['text_chunk']].to_csv(\"metadata.csv\", index=False)\nnp.save(\"embeddings.npy\", np.array(metadata_df['embedding'].tolist()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:28:27.872672Z","iopub.execute_input":"2025-04-19T21:28:27.872977Z","iopub.status.idle":"2025-04-19T21:28:28.724266Z","shell.execute_reply.started":"2025-04-19T21:28:27.872953Z","shell.execute_reply":"2025-04-19T21:28:28.723655Z"}},"outputs":[],"execution_count":null}]}